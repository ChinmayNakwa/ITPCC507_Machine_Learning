{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d181c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789b12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Initialize or reset the board\"\"\"\n",
    "        self.board = [' '] * 9  # 3x3 board\n",
    "        self.current_player = 'X'\n",
    "        return self.get_state()\n",
    "\n",
    "    def available_actions(self):\n",
    "        \"\"\"Return available positions\"\"\"\n",
    "        return [i for i, cell in enumerate(self.board) if cell == ' ']\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Make a move\"\"\"\n",
    "        if self.board[action] != ' ':\n",
    "            return self.get_state(), -10, True  # Invalid move penalty\n",
    "\n",
    "        self.board[action] = self.current_player\n",
    "        winner = self.check_winner()\n",
    "        done = winner is not None or ' ' not in self.board\n",
    "        reward = 0\n",
    "\n",
    "        if winner == self.current_player:\n",
    "            reward = 1\n",
    "        elif done:\n",
    "            reward = 0.5  # Draw reward\n",
    "\n",
    "        # Switch player\n",
    "        self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "    def check_winner(self):\n",
    "        \"\"\"Check if a player has won\"\"\"\n",
    "        wins = [\n",
    "            (0, 1, 2), (3, 4, 5), (6, 7, 8),  # rows\n",
    "            (0, 3, 6), (1, 4, 7), (2, 5, 8),  # columns\n",
    "            (0, 4, 8), (2, 4, 6)              # diagonals\n",
    "        ]\n",
    "        for (a, b, c) in wins:\n",
    "            if self.board[a] == self.board[b] == self.board[c] != ' ':\n",
    "                return self.board[a]\n",
    "        return None\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"Return tuple representation of the board\"\"\"\n",
    "        return tuple(self.board)\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Display the board\"\"\"\n",
    "        print(\"\\n\")\n",
    "        for i in range(0, 9, 3):\n",
    "            print(self.board[i], \"|\", self.board[i+1], \"|\", self.board[i+2])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f95bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "# b. Defining Q-learning\n",
    "Q = {}\n",
    "alpha = 0.1      # learning rate\n",
    "gamma = 0.9      # discount factor\n",
    "epsilon = 0.1    # exploration\n",
    "\n",
    "def get_Q(state, action):\n",
    "    return Q.get((state, action), 0.0)\n",
    "\n",
    "# c. Training the model\n",
    "env = TicTacToe()\n",
    "for episode in range(50000):\n",
    "    state = env.reset()\n",
    "    player = 'X'\n",
    "    while True:\n",
    "        actions = env.available_actions()\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            q_vals = [get_Q(state, a) for a in actions]\n",
    "            action = actions[np.argmax(q_vals)]\n",
    "        next_state, reward, done = env.step(action, player)\n",
    "        if done:\n",
    "            Q[(state, action)] = get_Q(state, action) + alpha * (reward - get_Q(state, action))\n",
    "            break\n",
    "        opp_action = random.choice(env.available_actions())\n",
    "        next_state, opp_reward, done = env.step(opp_action, 'O')\n",
    "        if done:\n",
    "            reward = -1 if opp_reward == 1 else 0\n",
    "            Q[(state, action)] = get_Q(state, action) + alpha * (reward - get_Q(state, action))\n",
    "            break\n",
    "        next_actions = env.available_actions()\n",
    "        q_next = max([get_Q(next_state, a) for a in next_actions]) if next_actions else 0\n",
    "        Q[(state, action)] = get_Q(state, action) + alpha * (reward + gamma * q_next - get_Q(state, action))\n",
    "        state = next_state\n",
    "\n",
    "print(\"Training done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8700a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Testing the model\n",
    "def play_game():\n",
    "    env = TicTacToe()\n",
    "    state = env.reset()\n",
    "    player = 'X'\n",
    "    while True:\n",
    "        actions = env.available_actions()\n",
    "        \n",
    "        q_vals = [get_Q(state, a) for a in actions]\n",
    "        action = actions[np.argmax(q_vals)]\n",
    "        state, reward, done = env.step(action, player)\n",
    "        if done:\n",
    "            print(np.array(state).reshape(3,3))\n",
    "            print(\"Result:\", \"Win\" if reward==1 else \"Draw\" if reward==0.5 else \"Lose\")\n",
    "            break\n",
    "        opp_action = random.choice(env.available_actions())\n",
    "        state, reward, done = env.step(opp_action, 'O')\n",
    "        if done:\n",
    "            print(np.array(state).reshape(3,3))\n",
    "            print(\"Result:\", \"Lose\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b021ae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['X' 'X' 'X']\n",
      " [' ' ' ' 'O']\n",
      " [' ' 'O' ' ']]\n",
      "Result: Win\n",
      "[['X' 'X' 'X']\n",
      " [' ' ' ' 'O']\n",
      " ['O' ' ' ' ']]\n",
      "Result: Win\n",
      "[['X' 'X' 'X']\n",
      " [' ' ' ' 'O']\n",
      " [' ' 'O' ' ']]\n",
      "Result: Win\n"
     ]
    }
   ],
   "source": [
    "# e. Play a few test games\n",
    "for _ in range(3):\n",
    "    play_game()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509be46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4451c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
