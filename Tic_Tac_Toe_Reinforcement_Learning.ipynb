{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d181c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789b12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Initialize or reset the board\"\"\"\n",
    "        self.board = [' '] * 9  # 3x3 board\n",
    "        self.current_player = 'X'\n",
    "        return self.get_state()\n",
    "\n",
    "    def available_actions(self):\n",
    "        \"\"\"Return available positions\"\"\"\n",
    "        return [i for i, cell in enumerate(self.board) if cell == ' ']\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Make a move\"\"\"\n",
    "        if self.board[action] != ' ':\n",
    "            return self.get_state(), -10, True  # Invalid move penalty\n",
    "\n",
    "        self.board[action] = self.current_player\n",
    "        winner = self.check_winner()\n",
    "        done = winner is not None or ' ' not in self.board\n",
    "        reward = 0\n",
    "\n",
    "        if winner == self.current_player:\n",
    "            reward = 1\n",
    "        elif done:\n",
    "            reward = 0.5  # Draw reward\n",
    "\n",
    "        # Switch player\n",
    "        self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "    def check_winner(self):\n",
    "        \"\"\"Check if a player has won\"\"\"\n",
    "        wins = [\n",
    "            (0, 1, 2), (3, 4, 5), (6, 7, 8),  # rows\n",
    "            (0, 3, 6), (1, 4, 7), (2, 5, 8),  # columns\n",
    "            (0, 4, 8), (2, 4, 6)              # diagonals\n",
    "        ]\n",
    "        for (a, b, c) in wins:\n",
    "            if self.board[a] == self.board[b] == self.board[c] != ' ':\n",
    "                return self.board[a]\n",
    "        return None\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"Return tuple representation of the board\"\"\"\n",
    "        return tuple(self.board)\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Display the board\"\"\"\n",
    "        print(\"\\n\")\n",
    "        for i in range(0, 9, 3):\n",
    "            print(self.board[i], \"|\", self.board[i+1], \"|\", self.board[i+2])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f95bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.3, gamma=0.9, epsilon=1.0, epsilon_min=0.1, decay=0.995):\n",
    "        self.Q = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.decay = decay\n",
    "\n",
    "    def get_q(self, state, action):\n",
    "        return self.Q.get((state, action), 0.0)\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_actions)\n",
    "        qs = [self.get_q(state, a) for a in available_actions]\n",
    "        max_q = max(qs)\n",
    "        return random.choice([a for a, q in zip(available_actions, qs) if q == max_q])\n",
    "\n",
    "    def update(self, state, action, reward, next_state, next_actions, done):\n",
    "        old_q = self.get_q(state, action)\n",
    "        future_q = 0 if done else max([self.get_q(next_state, a) for a in next_actions])\n",
    "        new_q = old_q + self.alpha * (reward + self.gamma * future_q - old_q)\n",
    "        self.Q[(state, action)] = new_q\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8700a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 | Epsilon=0.995\n",
      "Episode 5000 | Epsilon=0.100\n",
      "Episode 10000 | Epsilon=0.100\n",
      "Episode 15000 | Epsilon=0.100\n",
      "Episode 20000 | Epsilon=0.100\n",
      "Episode 25000 | Epsilon=0.100\n",
      "Episode 30000 | Epsilon=0.100\n",
      "Episode 35000 | Epsilon=0.100\n",
      "Episode 40000 | Epsilon=0.100\n",
      "Episode 45000 | Epsilon=0.100\n",
      "\n",
      "‚úÖ Training completed!\n",
      "Wins: 46634, Draws: 2142, Losses: 1224\n",
      "Q-table saved as 'tictactoe_qtable.pkl'.\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe()\n",
    "agent = QLearningAgent()\n",
    "\n",
    "episodes = 50000\n",
    "win, draw, lose = 0, 0, 0\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        actions = env.available_actions()\n",
    "        action = agent.choose_action(state, actions)\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        # Opponent plays randomly\n",
    "        if not done:\n",
    "            opp_actions = env.available_actions()\n",
    "            if opp_actions:\n",
    "                opp_action = random.choice(opp_actions)\n",
    "                next_state, opp_reward, done = env.step(opp_action)\n",
    "                if opp_reward == 1:  # Opponent wins\n",
    "                    reward = -1\n",
    "                    done = True\n",
    "\n",
    "        next_actions = env.available_actions()\n",
    "        agent.update(state, action, reward, next_state, next_actions, done)\n",
    "        state = next_state\n",
    "\n",
    "    agent.decay_epsilon()\n",
    "\n",
    "    # Track performance\n",
    "    if reward == 1:\n",
    "        win += 1\n",
    "    elif reward == 0.5:\n",
    "        draw += 1\n",
    "    elif reward == -1:\n",
    "        lose += 1\n",
    "\n",
    "    if episode % 5000 == 0:\n",
    "        print(f\"Episode {episode} | Epsilon={agent.epsilon:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Wins: {win}, Draws: {draw}, Losses: {lose}\")\n",
    "\n",
    "# Save Q-table\n",
    "with open(\"tictactoe_qtable.pkl\", \"wb\") as f:\n",
    "    pickle.dump(agent.Q, f)\n",
    "print(\"Q-table saved as 'tictactoe_qtable.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b021ae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéÆ Testing trained agent vs Random Player\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  | O |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  | O |  \n",
      "X | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  | O |  \n",
      "X | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  | O |  \n",
      "X | X | X\n",
      "  | O |  \n",
      "\n",
      "\n",
      "Agent (X) wins ‚úÖ\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "X | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O |   |  \n",
      "X | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O |   |  \n",
      "X | X | X\n",
      "  | O |  \n",
      "\n",
      "\n",
      "Agent (X) wins ‚úÖ\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "X | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O |   |  \n",
      "X | X |  \n",
      "  | O |  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O |   |  \n",
      "X | X | X\n",
      "  | O |  \n",
      "\n",
      "\n",
      "Agent (X) wins ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "agent.epsilon = 0.0  # Disable exploration\n",
    "env = TicTacToe()\n",
    "\n",
    "print(\"\\nüéÆ Testing trained agent vs Random Player\")\n",
    "\n",
    "for game in range(3):  # play 3 sample games\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    env.render()\n",
    "\n",
    "    while not done:\n",
    "        actions = env.available_actions()\n",
    "        action = agent.choose_action(state, actions)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        env.render()\n",
    "\n",
    "        if done:\n",
    "            if reward == 1:\n",
    "                print(\"Agent (X) wins ‚úÖ\")\n",
    "            elif reward == 0.5:\n",
    "                print(\"It's a draw üòê\")\n",
    "            else:\n",
    "                print(\"Agent lost ‚ùå\")\n",
    "            break\n",
    "\n",
    "        # Opponent move\n",
    "        opp_actions = env.available_actions()\n",
    "        if opp_actions:\n",
    "            opp_action = random.choice(opp_actions)\n",
    "            next_state, reward, done = env.step(opp_action)\n",
    "            env.render()\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    print(\"Opponent (O) wins ‚ùå\")\n",
    "                elif reward == 0.5:\n",
    "                    print(\"It's a draw üòê\")\n",
    "                break\n",
    "        state = next_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8509be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéÆ Let's play Tic-Tac-Toe! You are O, AI is X\n",
      "Board positions:\n",
      "0 | 1 | 2\n",
      "3 | 4 | 5\n",
      "6 | 7 | 8\n",
      "\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "ü§ñ AI's Move:\n",
      "\n",
      "\n",
      "  |   |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "üßç‚Äç‚ôÇÔ∏è Your Move:\n",
      "\n",
      "\n",
      "  |   | O\n",
      "  | X |  \n",
      "  |   |  \n",
      "\n",
      "\n",
      "ü§ñ AI's Move:\n",
      "\n",
      "\n",
      "  |   | O\n",
      "  | X |  \n",
      "  |   | X\n",
      "\n",
      "\n",
      "üßç‚Äç‚ôÇÔ∏è Your Move:\n",
      "\n",
      "\n",
      "O |   | O\n",
      "  | X |  \n",
      "  |   | X\n",
      "\n",
      "\n",
      "ü§ñ AI's Move:\n",
      "\n",
      "\n",
      "O | X | O\n",
      "  | X |  \n",
      "  |   | X\n",
      "\n",
      "\n",
      "üßç‚Äç‚ôÇÔ∏è Your Move:\n",
      "\n",
      "\n",
      "O | X | O\n",
      "  | X |  \n",
      "  | O | X\n",
      "\n",
      "\n",
      "ü§ñ AI's Move:\n",
      "\n",
      "\n",
      "O | X | O\n",
      "  | X | X\n",
      "  | O | X\n",
      "\n",
      "\n",
      "üßç‚Äç‚ôÇÔ∏è Your Move:\n",
      "\n",
      "\n",
      "O | X | O\n",
      "O | X | X\n",
      "  | O | X\n",
      "\n",
      "\n",
      "ü§ñ AI's Move:\n",
      "\n",
      "\n",
      "O | X | O\n",
      "O | X | X\n",
      "X | O | X\n",
      "\n",
      "\n",
      "It's a draw üòê\n"
     ]
    }
   ],
   "source": [
    "def play_vs_agent(agent):\n",
    "    env = TicTacToe()\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    agent.epsilon = 0.0  # Disable exploration\n",
    "\n",
    "    print(\"\\nüéÆ Let's play Tic-Tac-Toe! You are O, AI is X\")\n",
    "    print(\"Board positions:\\n0 | 1 | 2\\n3 | 4 | 5\\n6 | 7 | 8\\n\")\n",
    "    env.render()\n",
    "\n",
    "    while not done:\n",
    "        # Agent (X) plays\n",
    "        if env.current_player == 'X':\n",
    "            actions = env.available_actions()\n",
    "            action = agent.choose_action(state, actions)\n",
    "            state, reward, done = env.step(action)\n",
    "            print(\"ü§ñ AI's Move:\")\n",
    "            env.render()\n",
    "\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    print(\"AI wins! ü§ñüèÜ\")\n",
    "                elif reward == 0.5:\n",
    "                    print(\"It's a draw üòê\")\n",
    "                else:\n",
    "                    print(\"You win! üéâ\")\n",
    "                break\n",
    "\n",
    "        # Human (O) plays\n",
    "        else:\n",
    "            valid_move = False\n",
    "            while not valid_move:\n",
    "                try:\n",
    "                    pos = int(input(\"Enter your move (0-8): \"))\n",
    "                    if pos in env.available_actions():\n",
    "                        valid_move = True\n",
    "                    else:\n",
    "                        print(\"‚ùå Invalid move, try again.\")\n",
    "                except ValueError:\n",
    "                    print(\"‚ö†Ô∏è Enter a number between 0 and 8.\")\n",
    "            \n",
    "            state, reward, done = env.step(pos)\n",
    "            print(\"üßç‚Äç‚ôÇÔ∏è Your Move:\")\n",
    "            env.render()\n",
    "\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    print(\"You win! üéâ\")\n",
    "                elif reward == 0.5:\n",
    "                    print(\"It's a draw üòê\")\n",
    "                else:\n",
    "                    print(\"AI wins! ü§ñüèÜ\")\n",
    "                break\n",
    "\n",
    "# Run the game after training\n",
    "play_vs_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4451c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
